{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### King County - start urban farming club "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### close to a city and affordable houses with large lots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "sns.set(style='white')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### background check on the region to pick the citys of intrest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "us_cities = pd.read_csv('data/uscities.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the citys from : https://simplemaps.com/data/us-cities\n",
    "c = us_cities[(us_cities.state_id == 'WA') & (us_cities.county_name == 'King')]\n",
    "\n",
    "# main filter 20k population - leave seattle out\n",
    "cns = c[(c.city != 'Seattle') & (c.population > 20000)]\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(12,8))\n",
    "plt.bar(cns.city,cns.population)\n",
    "plt.xticks(cns.city, rotation='vertical', size=12)\n",
    "plt.xlabel('city')\n",
    "plt.ylabel('population')\n",
    "plt.title(f'kink county city pop. (without Seattle {c.population.max()})')\n",
    "plt.gcf().subplots_adjust(bottom=0.25)\n",
    "plt.savefig('./pic_exports/CitySelect_Population_no_Seattle', dpi=300)\n",
    "plt.show()\n",
    "cns.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the reduced data set\n",
    "Selcted_cities = c[(c.population > 20000)]\n",
    "Selcted_cities.shape\n",
    "Selcted_cities.to_csv('data/King_county_city_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load House price data and correlate to selected citys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw = pd.read_csv('data/King_County_House_prices_dataset.csv')\n",
    "city_data =  pd.read_csv('data/King_county_city_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just check if the data some how match in lat and long...\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.scatter(x='long',y='lat',data=df_raw[df_raw.long < -121.7])\n",
    "plt.scatter(x='lng',y='lat',data=city_data)\n",
    "plt.axis('equal')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get distance to city "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add coordinats as tuple\n",
    "df_raw['coord'] = list(zip(df_raw.lat, df_raw.long))\n",
    "city_data['coord'] = list(zip(city_data.lat, city_data.lng))\n",
    "df_raw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this takes a little time !!!\n",
    "# calc geo distance from city center to each house\n",
    "import geopy.distance\n",
    "def distto(c1, c2):\n",
    "    return geopy.distance.vincenty(c1, c2).km\n",
    "\n",
    "for cn in city_data['city']:\n",
    "    city_coord = city_data[city_data.city == cn].coord\n",
    "    df_raw[cn] = pd.Series(df_raw.coord.apply(lambda x: distto(x,city_coord)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify coordinates\n",
    "city = 'Seattle'\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.scatter(x='long',y='lat',data=df_raw[df_raw.long < -121.7])\n",
    "plt.scatter(x='long',y='lat',data=df_raw[df_raw[city] < 10])\n",
    "plt.scatter(x='lng',y='lat',data=city_data[city_data.city == city])\n",
    "d = city_data[city_data.city != city]\n",
    "plt.scatter(x='lng',y='lat',data=d[d.city != city])\n",
    "for c,lat,lng in zip(d.city,d.lat,d.lng):\n",
    "    plt.text(lng,lat,c, fontsize=12)\n",
    "plt.axis('equal')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unit column adding for EU units m^2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Unit_sqf2sqm = 0.092903\n",
    "Soccerfield = 68*105"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw['sqm_living'] =  df_raw.sqft_living * Unit_sqf2sqm\n",
    "df_raw['sqm_lot'] =  df_raw.sqft_lot * Unit_sqf2sqm\n",
    "df_raw['sqm_lot_soccer'] =  (df_raw.sqft_lot * Unit_sqf2sqm)/Soccerfield\n",
    "df_raw['sqm_above'] =  df_raw.sqft_above * Unit_sqf2sqm\n",
    "df_raw['sqm_living15'] =  df_raw.sqft_living15 * Unit_sqf2sqm\n",
    "df_raw['sqm_lot15'] =  df_raw.sqft_lot15 * Unit_sqf2sqm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding a price in million and thousend doller"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw['Mprice'] = df_raw.price/1e6\n",
    "df_raw['kprice'] = df_raw.price/1e3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## clean yr_renovated and add time since last renovated or age  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# deal with NaN\n",
    "df_raw.yr_renovated.isnull().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw.yr_renovated[df_raw.yr_renovated.isnull()] = 0\n",
    "df_raw.yr_renovated.isnull().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add the removation_age \n",
    "# now - year renovated*is renovated - year build\n",
    "def RenoAge(built,Reno):\n",
    "    Now = 2015\n",
    "    if Reno==0.:\n",
    "        RenoAge = Now-built\n",
    "    else:\n",
    "        RenoAge = Now-Reno\n",
    "    return RenoAge\n",
    "\n",
    "df_raw['renovated'] = df_raw.yr_renovated!=0\n",
    "df_raw['renovation_age'] = \\\n",
    "    df_raw.apply(lambda x: RenoAge(x.yr_built,x.yr_renovated), axis= 1)\n",
    "\n",
    "df_raw[['renovation_age','renovated','yr_built','yr_renovated']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw['renovation_age'].hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overall season of sales split date of sale "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the month\n",
    "import re\n",
    "temp = df_raw['date']\n",
    "temp = temp.apply(lambda x: int(re.findall('\\d+',x)[0]))\n",
    "df_raw['sale_month'] = temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the year\n",
    "import re\n",
    "temp = df_raw['date']\n",
    "temp = temp.apply(lambda x: int(re.findall('\\d+',x)[2]))\n",
    "df_raw['sale_year'] = temp\n",
    "df_raw.sale_year.unique() \n",
    "# sales dates are from 2014-2015"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get impression over the price season ...\n",
    "def plotMaxMeanMin(df_p,key,safeto=None):\n",
    "    keys = [zipcode for zipcode, df in df_p.groupby(['sale_month'])]\n",
    "    keys = [str(z) for z in keys]\n",
    "    plt.bar(keys,df_p.groupby([key]).max()['Mprice'])\n",
    "    plt.bar(keys,df_p.groupby([key]).mean()['Mprice'])\n",
    "    plt.bar(keys,df_p.groupby([key]).min()['Mprice'])\n",
    "    plt.ylabel('max/mean/min price in USD (M$)')\n",
    "    plt.xlabel(key)\n",
    "    plt.xticks(keys, rotation='vertical', size=10)\n",
    "    if safeto:\n",
    "        plt.savefig(safeto, dpi=300)\n",
    "    plt.show()\n",
    "    \n",
    "plotMaxMeanMin(df_raw,'sale_month','./pic_exports/Sale_Season_Overall_1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotMaxMeanMin(df_raw[df_raw.Mprice < 1],'sale_month','./pic_exports/Sale_Season_Overall_2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selecting the rigion\n",
    "\n",
    "- needed space at least 12000 m^2 for lot\n",
    "- price limit somwehre ... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# price limit reasonabel \n",
    "g = sns.jointplot(x='sqm_lot',y='Mprice',data=df_raw[df_raw.price < 2.5e6],kind='scatter')\n",
    "# good box is bellow\n",
    "\n",
    "# draw the red line\n",
    "x0, x1 = g.ax_joint.get_xlim()\n",
    "y0, y1 = g.ax_joint.get_ylim()\n",
    "price_limit = 1.25 # set price limit by eye\n",
    "g.ax_joint.plot([x0,x1], [price_limit,price_limit], ':r')\n",
    "\n",
    "plt.savefig('./pic_exports/ReasonablePrice', dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "here also a cut of for extream large lots would be a good idea for the possible linear rel. extraction..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw.sqm_lot.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### create basic stats for fitting house for all possible citys \n",
    "to genrate to find best city in regards to amount of found houses price limit and close to the city center\n",
    "this also acts as outlyer filter indirectly..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO fill the rest of basic stats\n",
    "lot_thres = 12000\n",
    "\n",
    "df_stat = pd.DataFrame(columns=['hits','population','low_price','low_price_lot','mean_lot'], index=city_data.city)\n",
    "for city in city_data.city:\n",
    "    df = df_raw[(df_raw[city] < 10) & \n",
    "                (df_raw[city] > 2) & \n",
    "                (df_raw['sqm_lot'] > lot_thres) & \n",
    "                (df_raw['Mprice'] < price_limit)]\n",
    "\n",
    "    df_stat.at[city,'hits'] = df.shape[0]\n",
    "    df_stat.at[city,'low_price'] = df.price.min()\n",
    "    df_stat.at[city,'low_price_lot'] = df[df.price == df.price.min()].sqft_lot.max()\n",
    "    #print(city)\n",
    "    a = city_data[city_data.city.str.contains(city)].population.max()\n",
    "    df_stat.at[city,'population'] = a\n",
    "    \n",
    "df_stat.hits.plot.bar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### find metric to mage city choice based on availability and proximity "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax1 = plt.subplots(figsize=(12,8))\n",
    "ax2 = ax1.twinx() # left and right y axis\n",
    "keys = df_stat.index\n",
    "ax2.plot(keys,df_stat.population/1000,'r')\n",
    "ax1.bar(keys,df_stat.hits*df_stat.population/10000)\n",
    "ax1.bar(keys,df_stat.hits*1)\n",
    "ax1.set_xlabel('city')\n",
    "ax2.set_ylabel('pop. / 1000', color='r')\n",
    "ax2.set_ylim([0,200])\n",
    "ax1.set_ylabel('hits and hits*pop./10000 ', color='b')\n",
    "ax1.set_xticklabels(keys, rotation='vertical', size=12)\n",
    "\n",
    "plt.savefig('./pic_exports/CitySelect_Pass2ByHitsWithMetric', dpi=300)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### continue with top 5 citys and create the dataframe with selected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "city=['Auburn','Kent', 'Sammamish', 'Maple Valley', 'Renton'] \n",
    "df_select = df_raw[(((df_raw[city[0]] < 10) & (df_raw[city[0]] > 1)) | \n",
    "             ((df_raw[city[1]] < 10) & (df_raw[city[1]] > 1)) |\n",
    "             ((df_raw[city[4]] < 10) & (df_raw[city[4]] > 1)) |\n",
    "             ((df_raw[city[2]] < 10) & (df_raw[city[2]] > 1)) |\n",
    "             ((df_raw[city[3]] < 10) & (df_raw[city[3]] > 1)) ) & \n",
    "                (df_raw['sqm_lot'] > lot_thres) & \n",
    "                (df_raw['Mprice'] < price_limit)]\n",
    "\n",
    "df_all_range = df_raw[(((df_raw[city[0]] < 10) & (df_raw[city[0]] > 1)) | \n",
    "             ((df_raw[city[1]] < 10) & (df_raw[city[1]] > 1)) |\n",
    "             ((df_raw[city[4]] < 10) & (df_raw[city[4]] > 1)) |\n",
    "             ((df_raw[city[2]] < 10) & (df_raw[city[2]] > 1)) |\n",
    "             ((df_raw[city[3]] < 10) & (df_raw[city[3]] > 1)) )  ]\n",
    "\n",
    "print(df_select.shape)\n",
    "print(df_all_range.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drawing on the Map to visulize the selection against all "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## adding shape file to plot a card\n",
    "import shapefile as shp  # Requires the pyshp package\n",
    "sf = shp.Reader(\"./data/Zipcodes_for_King_County_and_Surrounding_Area__zipcode_area.shp\")\n",
    "\n",
    "#ploting the card as lines plot\n",
    "plt.figure(figsize=(12,12))\n",
    "for shape in sf.shapeRecords():\n",
    "    x = [i[0] for i in shape.shape.points[:]]\n",
    "    y = [i[1] for i in shape.shape.points[:]]\n",
    "    plt.plot(x,y,'gray', alpha=0.6)\n",
    "    \n",
    "# ploting all, close range, and selction\n",
    "plt.scatter(x='long',y='lat',data=df_raw[df_raw.long < -121.7],label= 'all', alpha=0.6)\n",
    "plt.scatter(x='long',y='lat',data=df_all_range, label='all in range', alpha=0.5, color='g')\n",
    "plt.scatter(x='long',y='lat',data=df_select, label='hits', color='r')\n",
    "\n",
    "# adding city names\n",
    "d = city_data\n",
    "plt.scatter(x='lng',y='lat',data=d ,marker='+', label='city center', color='k')\n",
    "for c,lat,lng in zip(d.city,d.lat,d.lng):\n",
    "    plt.text(lng,lat,c, fontsize=15)\n",
    "plt.legend()\n",
    "#plt.axis('equal')\n",
    "\n",
    "# finde tune the zoom\n",
    "plt.ylim(47.1,47.1+0.8)\n",
    "plt.xlim(-122.5,-122.5+0.8)\n",
    "\n",
    "plt.savefig('./pic_exports/CitySelect_Map', dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### check the price season"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotMaxMeanMin(df_select[df_select.Mprice < 2],'sale_month','./pic_exports/CitySelectedSale_Season_Overall_2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,8))\n",
    "sns.boxplot(x=\"sale_month\", y=\"Mprice\", data=df_select)\n",
    "plt.savefig('./pic_exports/CitySelect_sales_month_box', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the freq. of sales per month\n",
    "\n",
    "# TODO add better plot\n",
    "df_select.sale_month.hist(bins=range(1,13))\n",
    "plt.xticks(range(1,13))\n",
    "plt.xlabel('month')\n",
    "plt.ylabel('freq. sales')\n",
    "plt.savefig('./pic_exports/CitySelect_sales_month_hist', dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### calc the portion of the selection to indecate chances of getting a hit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hit_chances = pd.DataFrame()\n",
    "i = pd.Index(['all', 'selected', 'all_in_range'])\n",
    "df_hit_chances['hits'] = pd.Series([df_raw.shape[0],df_select.shape[0],df_all_range.shape[0]],\n",
    "                    index=i)\n",
    "\n",
    "df_hit_chances['prop total'] = pd.Series([df_raw.shape[0]/df_raw.shape[0],df_select.shape[0]/df_raw.shape[0],df_all_range.shape[0]/df_raw.shape[0]],\n",
    "                    index=i)\n",
    "\n",
    "df_hit_chances['prop range'] = pd.Series([df_raw.shape[0]/df_all_range.shape[0],df_select.shape[0]/df_all_range.shape[0],df_all_range.shape[0]/df_all_range.shape[0]],\n",
    "                    index=i)\n",
    "\n",
    "#sns.heatmap(df_hit_chances)\n",
    "df_hit_chances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO - calc chances make table\n",
    "# add all in price range \n",
    "# all in size range\n",
    "chances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Looking for correlation - Find Price Indecators of houses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_select.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l_focus = ['price',\n",
    "           'sqm_lot',\n",
    "           'renovation_age',\n",
    "           'sqm_living',\n",
    "           'yr_built',\n",
    "           'Seattle',\n",
    "           'Bellevue',\n",
    "           'grade',\n",
    "           'condition',\n",
    "           'bathrooms',\n",
    "           'sale_month',\n",
    "           'floors']\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "sns.heatmap(df_select[l_focus].corr(),cmap='coolwarm',annot=True)\n",
    "\n",
    "# all chosen seem to have a impact expet sale_month..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(df_select[l_focus])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try to scale the price log this has not been used in the end ...\n",
    "df_select['priceLog'] = np.log(df_select.price)\n",
    "l_focus[0] = 'priceLog'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l_focus[0] = 'price'\n",
    "l_focus.append('Kent') # patching cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# explore bi var to price\n",
    "for e in l_focus:\n",
    "    sns.lmplot(y=l_focus[0],x=e,data=df_select)\n",
    "    plt.savefig('./pic_exports/Scatter_%s' %e, dpi=300)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Notebook cell to pick variables for the inital Model\n",
    "\n",
    "# primary correlation\n",
    "# sqm_living\n",
    "# bathrooms\n",
    "# grade ( can be kepts as is)\n",
    "# renovation_age\n",
    "\n",
    "\n",
    "# mini impact distance to the biggest citys\n",
    "# just take Seattle\n",
    "\n",
    "\n",
    "# special attention\n",
    "# sqm_lot does not drive the price - TODO make plot for presentaion\n",
    "# as expected sale month\n",
    "\n",
    "# catecoricals \n",
    "#floors\n",
    "\n",
    "#condtion\n",
    "#(grade)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## build a OLS model - Tunning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn import metrics\n",
    "import statsmodels.api as sm\n",
    "\n",
    "#https://stats.stackexchange.com/questions/58391/mean-absolute-percentage-error-mape-in-scikit-learn\n",
    "def mean_absolute_percentage_error(y_true, y_pred): \n",
    "    return np.round(np.mean(np.abs((y_true - y_pred) / y_true)) * 100,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the variables\n",
    "y = df_select['price']\n",
    "#y = df_select['priceLog']\n",
    "#X = df_select[['sqm_living','Seattle']]\n",
    "#X = df_select[['sqm_living','bathrooms', \n",
    "#               'Seattle', 'grade', 'renovation_age' ]]\n",
    "\n",
    "# Split Training set\n",
    "X = df_select[['sqm_living','bathrooms', 'yr_built',\n",
    "         'Seattle', 'grade', 'renovation_age' , 'Auburn','Kent', 'Sammamish', 'Maple Valley', 'Renton' ]]\n",
    "X_train, X_test, y_train, y_test = \\\n",
    "train_test_split(X, y, test_size=0.3, random_state=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit a model\n",
    "lm = LinearRegression()\n",
    "lm.fit(X_train,y_train)\n",
    "#lm = sm.OLS(y_train ,X_train).fit() # sklearn has not the summery feedback ... can be toggled here\n",
    "y_hat_t = lm.predict( X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do prediction and give some feedback on the fit\n",
    "y_hat = lm.predict( X_test)\n",
    "sns.regplot(y_test,y_hat)\n",
    "plt.xlabel('Y Test')\n",
    "plt.ylabel('Predicted Y')\n",
    "plt.show()\n",
    "sns.distplot((y_test-y_hat)/1000,bins=20);\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# explore coeffs of the model (sklearn model)\n",
    "coeffecients = pd.DataFrame(lm.coef_,X.columns)\n",
    "coeffecients.columns = ['Coeffecient']\n",
    "coeffecients\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try to make a simple indcator list to transport insite of the the coeff  (sklearn model)\n",
    "# TODO better way would be to normilize before fitting...\n",
    "def dir_exp(x):\n",
    "    if x>0:\n",
    "        return 'increase increases price'\n",
    "    else:\n",
    "        return 'increase reduces price'\n",
    "coeffexp = coeffecients.Coeffecient.apply(lambda x: dir_exp(x))\n",
    "coeffexp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get summery from statsmodel.api (not working with sklearn model !!) \n",
    "# lm.summary() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build feedback Table on model qualty\n",
    "ModelMetric = pd.DataFrame(columns=['Model Metric', 'Data Stat'])\n",
    "ModelMetric.at['MAE($)','Model Metric'] = (metrics.mean_absolute_error(y_test, y_hat))\n",
    "ModelMetric.at['MPE(%)','Model Metric'] = mean_absolute_percentage_error(y_test, (y_hat))\n",
    "ModelMetric.at['MSE','Model Metric'] = metrics.mean_squared_error(y_test, y_hat)\n",
    "ModelMetric.at['RMSE','Model Metric'] = np.sqrt(metrics.mean_squared_error(y_test, y_hat))\n",
    "ModelMetric.at['R2','Model Metric'] = metrics.r2_score(y_test, y_hat)\n",
    "ModelMetric.at['R2train','Model Metric'] = metrics.r2_score(y_train, y_hat_t)\n",
    "ModelMetric.at['abs. MEAfMean','Model Metric'] = y_train.mean()*mean_absolute_percentage_error(y_test, y_hat)/100\n",
    "ModelMetric.at['abs. MEAfMax','Model Metric'] = y_train.max()*mean_absolute_percentage_error(y_test, y_hat)/100\n",
    "ModelMetric.at['abs. MEAfMean','Data Stat'] = (y_train.mean())\n",
    "ModelMetric.at['abs. MEAfMax','Data Stat'] = (y_train.max())\n",
    "ModelMetric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# probing abslutes of the error...\n",
    "print(np.exp(y_train.mean())*metrics.mean_absolute_error(y_test, y_hat))\n",
    "print(np.exp(y_train.mean())*metrics.mean_absolute_error(y_train, y_hat_t))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try to Improve prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Test some feature combination to improve the fit\n",
    "\n",
    "def Train(xlist,y,df):   \n",
    "    y = df[y]\n",
    "    X = df[xlist]\n",
    "    X_train, X_test, y_train, y_test = \\\n",
    "    train_test_split(X, y, test_size=0.3, random_state=101)\n",
    "    #lm = LinearRegression()\n",
    "    lm = sm.OLS(y_train ,X_train).fit()\n",
    "    #lm.fit(X_train,y_train)\n",
    "    y_hat = lm.predict( X_test)\n",
    "    y_hat_t = lm.predict( X_train)\n",
    "\n",
    "    return mean_absolute_percentage_error(y_test, y_hat)\n",
    "\n",
    "y = 'price'\n",
    "xlist = ['sqm_living']\n",
    "print(xlist ,Train(xlist,y,df_select))\n",
    "\n",
    "y = 'price'\n",
    "xlist = ['sqm_living', 'renovation_age']\n",
    "print(xlist ,Train(xlist,y,df_select))\n",
    "\n",
    "\n",
    "y = 'price'\n",
    "xlist = ['sqm_living','bathrooms']\n",
    "print(xlist ,Train(xlist,y,df_select))\n",
    "\n",
    "y = 'price'\n",
    "xlist = ['sqm_living','grade','Seattle']\n",
    "print(xlist ,Train(xlist,y,df_select))\n",
    "\n",
    "\n",
    "y = 'price'\n",
    "xlist = ['grade','sqm_living','Seattle','renovation_age']\n",
    "print(xlist ,Train(xlist,y,df_select))\n",
    "\n",
    "\n",
    "y = 'price'\n",
    "xlist = ['sqm_living','bathrooms', \n",
    "         'Seattle', 'grade', 'renovation_age'  ]\n",
    "print(xlist ,Train(xlist,y,df_select))\n",
    "\n",
    "y = 'price'\n",
    "xlist = ['sqm_living','bathrooms', \n",
    "         'Seattle', 'grade', 'renovation_age' ,'Bellevue' ]\n",
    "print(xlist ,Train(xlist,y,df_select))\n",
    "\n",
    "y = 'price'\n",
    "xlist = ['sqm_living','bathrooms', \n",
    "         'Seattle', 'grade', 'yr_built' , 'renovation_age' ,'Bellevue', 'Auburn','Kent', 'Sammamish', 'Maple Valley', 'Renton' ]\n",
    "print(xlist ,Train(xlist,y,df_select))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reflection\n",
    "\n",
    "## Model  and future work \n",
    "the model was only used on very small subset of the data a compare against the all county data etc. should be done.\n",
    "\n",
    "the features used are not encoded for categorys like grade betroom etc at all - inital experments wehre explored but I returned to simpler means for now.\n",
    "\n",
    "the pure distance to the city center is intresting but the zipcode category or binning into the city could lead to more correlation and predictive insite. \n",
    "\n",
    "There seems some more potential in cleaning the data i.e. very old buildings. Or the outlyers in lot size ...\n",
    "\n",
    "The model is OLS linear for now no poly fit was tested. \n",
    "\n",
    "At one point experments with log of y was tested but on the reduced set the impact was not noticable (whiel experments in the Dev folder showed some promising results) \n",
    "\n",
    "To little work was done to clean the date from obvios outlyers and the 15 closed houses metrics wehre not used. Also the idea with soccerfield size compare for display was not used all because of time limits. \n",
    "\n",
    "The derived tendency of price increasing direction is partial based on to much variances and to little siginfacanse and need to redisigned as distance to a city is direction dependent and also clashes with other citys that are close ...\n",
    "\n",
    "\n",
    "## Methode to find best city\n",
    "even though the correlation of population and amount of found houses for the category works, it could have been more generic to explore the field better and compare i.e. more ctys close to finds multi. lots to combine to one big cluster of cheap neighbourhoods .... In extention to find i.e. 2 lots for combination could have been added for Seattle ( to not leave that marked untouched ..) \n",
    "\n",
    "is the lot size realy needed and is the price limit not still to high. Things to explore... the price limit reduction may help with outlyer in some features.\n",
    "\n",
    "The map plot is very basic and is not using any information from arrayers (like mean price zip code etc.) in the map. A map with a raster rather then all data points as scatter could be helpfull. The map shape file as shape rather then a outline may results in more insight ... \n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:nf] *",
   "language": "python",
   "name": "conda-env-nf-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
